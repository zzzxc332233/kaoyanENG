# app.py
import os, json, logging
from dotenv import load_dotenv
from tenacity import retry, wait_exponential, stop_after_attempt
import gradio as gr
from langchain_openai import ChatOpenAI
from langchain.schema import HumanMessage

# å¯¼å…¥æç¤ºè¯
from prompt import translation_prompt, short_prompt, long_prompt

# --- é…ç½®æ—¥å¿— ---
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s'
)
logger = logging.getLogger(__name__)

# æŠ‘åˆ¶ç¬¬ä¸‰æ–¹åº“çš„ DEBUG æ—¥å¿—
logging.getLogger("httpcore").setLevel(logging.WARNING)
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("urllib3").setLevel(logging.WARNING)

# --- åŠ è½½é…ç½® ---
load_dotenv()
logger.info("âœ… å·²åŠ è½½ .env æ–‡ä»¶")

with open("config.json", "r", encoding="utf-8") as f:
    cfg = json.load(f)["llm"]
logger.info(f"âœ… é…ç½®åŠ è½½å®Œæˆ: model={cfg['model']}, api_base={cfg['api_base']}")

API_KEY = os.getenv("DEEPSEEK_API_KEY")
if not API_KEY:
    logger.error("âŒ é”™è¯¯: è¯·åœ¨ .env è®¾ç½® DEEPSEEK_API_KEY")
    raise SystemExit("è¯·åœ¨ .env è®¾ç½® DEEPSEEK_API_KEY")
logger.info("âœ… API_KEY å·²åŠ è½½")

# è®¾ç½®ç¯å¢ƒå˜é‡ä¾› ChatOpenAI ä½¿ç”¨
os.environ["OPENAI_API_KEY"] = API_KEY
os.environ["OPENAI_API_BASE"] = cfg["api_base"]
logger.info("âœ… ç¯å¢ƒå˜é‡å·²è®¾ç½®")

# --- åˆå§‹åŒ– DeepSeek LLM ---
llm_config = {
    "model": cfg["model"],
    "temperature": cfg["temperature"],
    "max_tokens": cfg["max_tokens"]
}
llm = ChatOpenAI(**llm_config)
logger.info(f"âœ… LLM åˆå§‹åŒ–æˆåŠŸ: {llm_config}")

# --- æµ‹è¯• API è¿æ¥ ---
def test_api_connection():
    """æµ‹è¯•æ˜¯å¦èƒ½æˆåŠŸè¯·æ±‚ DeepSeek API"""
    logger.info("ğŸ” å¼€å§‹æµ‹è¯• API è¿æ¥...")
    try:
        test_message = HumanMessage(content="ä½ å¥½ï¼Œè¯·å›å¤ä¸€å¥ä¸­å›½å¤è¯—")
        response = llm.invoke([test_message])
        logger.info(f"âœ… API è¿æ¥æˆåŠŸ!")
        return {
            "status": "success",
            "message": "API è¿æ¥æˆåŠŸ",
            "response": response.content[:100] if response.content else "æ— å“åº”"
        }
    except Exception as e:
        logger.error(f"âŒ API è¿æ¥å¤±è´¥: {str(e)}")
        return {
            "status": "error",
            "message": f"API è¿æ¥å¤±è´¥: {str(e)}"
        }

# --- ç»Ÿä¸€è§£æ ---
@retry(wait=wait_exponential(min=1, max=20), stop=stop_after_attempt(4))
def parse_output(resp: str):
    logger.info(f"ğŸ“¥ æ”¶åˆ° LLM å“åº”: {resp[:200]}...")
    resp = resp.strip()
    # ç›´æ¥å°è¯• JSON
    try:
        result = json.loads(resp)
        logger.info(f"âœ… æˆåŠŸè§£æ JSON")
        return result
    except Exception as e1:
        logger.info(f"âš ï¸ ç›´æ¥è§£æå¤±è´¥ï¼Œå°è¯•æå– JSON ç‰‡æ®µ: {str(e1)}")
        # è£å‡ºç¬¬ä¸€ä¸ª { å’Œ æœ€åä¸€ä¸ª }
        s = resp.find("{")
        e = resp.rfind("}")
        if s >= 0 and e > s:
            try:
                extracted = resp[s:e+1]
                logger.info(f"ğŸ“ æå–çš„ JSON ç‰‡æ®µ: {extracted[:200]}...")
                result = json.loads(extracted)
                logger.info(f"âœ… æˆåŠŸè§£ææå–çš„ JSON ç‰‡æ®µ")
                return result
            except Exception as extract_err:
                logger.error(f"âŒ æå–çš„ JSON ç‰‡æ®µè§£æå¤±è´¥: {str(extract_err)}")
                logger.error(f"âŒ åŸå§‹å“åº”: {resp[:300]}")
                raise ValueError(f"æ— æ³•è§£æ JSONï¼š{resp[:200]}")
        logger.error(f"âŒ æœªæ‰¾åˆ° JSON ç‰‡æ®µï¼Œå®Œæ•´å“åº”: {resp}")
        raise ValueError(f"æ— æ³•è§£æ JSONï¼š{resp[:200]}")

def eval_translation(src, stu):
    logger.info("ğŸ“ [è‹±è¯‘æ±‰] å¼€å§‹è¯„ä¼°")
    try:
        prompt_text = translation_prompt.format(src_text=src, student_text=stu)
        response = llm.invoke([HumanMessage(content=prompt_text)])
        raw = response.content if isinstance(response.content, str) else str(response.content)
        logger.info(f"åŸå§‹å“åº”ç‰‡æ®µ: {raw[:200]}")
        try:
            result = parse_output(raw)
        except Exception as pe:
            logger.error(f"âŒ è§£æå¤±è´¥: {type(pe).__name__}: {repr(pe)}")
            raise
        logger.info(f"âœ… [è‹±è¯‘æ±‰] è¯„ä¼°å®Œæˆ, åˆ†æ•°: {result.get('score', 'N/A')}")
        return result
    except Exception as e:
        logger.error(f"âŒ [è‹±è¯‘æ±‰] è¯„ä¼°å¤±è´¥: {str(e)}", exc_info=True)
        return {"error": str(e)}

def eval_short(topic, stu):
    logger.info("ğŸ“ [å°ä½œæ–‡] å¼€å§‹è¯„ä¼°")
    try:
        prompt_text = short_prompt.format(topic=topic, student_text=stu)
        response = llm.invoke([HumanMessage(content=prompt_text)])
        raw = response.content if isinstance(response.content, str) else str(response.content)
        logger.info(f"åŸå§‹å“åº”ç‰‡æ®µ: {raw[:200]}")
        try:
            result = parse_output(raw)
        except Exception as pe:
            logger.error(f"âŒ è§£æå¤±è´¥: {type(pe).__name__}: {repr(pe)}")
            raise
        logger.info(f"âœ… [å°ä½œæ–‡] è¯„ä¼°å®Œæˆ, åˆ†æ•°: {result.get('score', 'N/A')}")
        return result
    except Exception as e:
        logger.error(f"âŒ [å°ä½œæ–‡] è¯„ä¼°å¤±è´¥: {str(e)}", exc_info=True)
        return {"error": str(e)}

def eval_long(topic, stu):
    logger.info("ğŸ“ [å¤§ä½œæ–‡] å¼€å§‹è¯„ä¼°")
    try:
        prompt_text = long_prompt.format(topic=topic, student_text=stu)
        response = llm.invoke([HumanMessage(content=prompt_text)])
        raw = response.content if isinstance(response.content, str) else str(response.content)
        logger.info(f"åŸå§‹å“åº”ç‰‡æ®µ: {raw[:200]}")
        try:
            result = parse_output(raw)
        except Exception as pe:
            logger.error(f"âŒ è§£æå¤±è´¥: {type(pe).__name__}: {repr(pe)}")
            raise
        logger.info(f"âœ… [å¤§ä½œæ–‡] è¯„ä¼°å®Œæˆ, åˆ†æ•°: {result.get('score', 'N/A')}")
        return result
    except Exception as e:
        logger.error(f"âŒ [å¤§ä½œæ–‡] è¯„ä¼°å¤±è´¥: {str(e)}", exc_info=True)
        return {"error": str(e)}

# --- WebUI ---
with gr.Blocks() as ui:
    gr.Markdown("## ğŸ“ è€ƒç ”è‹±è¯­ AI æ‰¹æ”¹ç³»ç»Ÿï¼ˆDeepSeek + LangChainï¼‰")

    with gr.Tab("ç³»ç»Ÿæ£€æµ‹"):
        gr.Markdown("### ğŸ” API è¿æ¥æµ‹è¯•")
        test_btn = gr.Button("æµ‹è¯• API è¿æ¥")
        test_output = gr.JSON(label="æµ‹è¯•ç»“æœ")
        test_btn.click(test_api_connection, outputs=test_output)

    with gr.Tab("è‹±è¯‘æ±‰"):
        t1 = gr.Textbox(label="åŸæ–‡ï¼ˆè‹±æ–‡ï¼‰", lines=6)
        t2 = gr.Textbox(label="è€ƒç”Ÿè¯‘æ–‡ï¼ˆä¸­æ–‡ï¼‰", lines=6)
        btn = gr.Button("æ‰¹æ”¹")
        out = gr.JSON()
        btn.click(eval_translation, [t1, t2], out)

    with gr.Tab("å°ä½œæ–‡"):
        s1 = gr.Textbox(label="é¢˜ç›®", lines=2)
        s2 = gr.Textbox(label="è€ƒç”Ÿä½œæ–‡", lines=10)
        btn2 = gr.Button("æ‰¹æ”¹")
        out2 = gr.JSON()
        btn2.click(eval_short, [s1, s2], out2)

    with gr.Tab("å¤§ä½œæ–‡"):
        l1 = gr.Textbox(label="é¢˜ç›®", lines=2)
        l2 = gr.Textbox(label="è€ƒç”Ÿä½œæ–‡", lines=15)
        btn3 = gr.Button("æ‰¹æ”¹")
        out3 = gr.JSON()
        btn3.click(eval_long, [l1, l2], out3)

ui.launch()
